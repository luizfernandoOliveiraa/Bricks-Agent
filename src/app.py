# app.py
import streamlit as st
from main import get_rag_chain, ensure_query_format
import mlflow
import os
import json

st.title("ğŸ—ï¸ Assistente Comercial de Materiais Industriais")
st.caption(
    "Recomenda materiais com base na aplicaÃ§Ã£o do cliente usando RAG + Vector Search"
)

st.set_page_config(page_title="ğŸ¤– Assistente Comercial de Materiais", layout="centered")


# InicializaÃ§Ã£o da Chain (cacheada)


@st.cache_resource
def initialize_chain():
    """Inicializa a chain RAG apenas uma vez."""
    return get_rag_chain()


chain = initialize_chain()

# HistÃ³rico de Chat
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": (
                "OlÃ¡! ğŸ‘‹\n\n"
                "Descreva a **aplicaÃ§Ã£o do material** que o cliente precisa "
                "(ex: suspensÃ£o de Ã´nibus, estrutura metÃ¡lica, torres de transmissÃ£o)."
            ),
        }
    ]

# Exibir histÃ³rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Entrada do UsuÃ¡rio
if user_query := st.chat_input("Descreva a necessidade do cliente..."):
    # Salva mensagem do usuÃ¡rio
    st.session_state.messages.append({"role": "user", "content": user_query})

    with st.chat_message("user"):
        st.write(user_query)

    # Processamento RAG
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” Buscando materiais mais adequados..."):
            with mlflow.start_run(run_name="material_rag_chat") as run:
                # Invoca a chain com a query do usuÃ¡rio, garantindo o formato correto
                input_data = {"messages": user_query}
                response = chain.invoke(input_data)

                # Log bÃ¡sico no MLflow
                mlflow.log_param("consulta_usuario", user_query)
                mlflow.log_param("run_id", run.info.run_id)

                # Tratamento da Resposta (JSON)

                st.subheader("ğŸ“Œ Resposta do Assistente")
                st.write(response)
                st.session_state.messages.append(
                    {
                        "role": "assistant",
                        "content": response,
                    }
                )

# Sidebar â€“ InformaÃ§Ãµes TÃ©cnicas
with st.sidebar:
    st.header("âš™ï¸ ConfiguraÃ§Ãµes TÃ©cnicas")
    st.write(f"**LLM Endpoint:** `{os.getenv('LLM_ENDPOINT')}`")
    st.write(f"**Vector Search Endpoint:** `{os.getenv('VS_ENDPOINT')}`")
    st.write(f"**Ãndice:** `{os.getenv('INDEX_NAME')}`")
    st.markdown("---")
    st.caption(
        "O agente utiliza RAG com foco na descriÃ§Ã£o de uso dos materiais "
        "para apoiar o time comercial."
    )
